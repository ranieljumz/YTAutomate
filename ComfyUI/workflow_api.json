{
  "1": {
    "inputs": {
      "unet_name": "flux1-dev-fp8-e4m3fn.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "UNETLoader"
    }
  },
  "4": {
    "inputs": {
      "clip_name1": "t5xxl_fp8_e4m3fn.safetensors",
      "clip_name2": "ViT-L-14-BEST-smooth-GmP-TE-only-HF-format.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "5": {
    "inputs": {
      "text": "A fluffy, 50% white, 50% gray Ragdoll cat, with large, expressive eyes, rests peacefully on a soft, plush throw blanket, creating a gentle contrast between the light and dark hues of its fur.  Its long, silky coat shimmers in the soft light, and its paws, subtly tipped in the same gray tones, have a delicate texture as they rest gently against the blanket. The cat's posture is relaxed, its tail gently swishing in slow, languid movements.",
      "clip": [
        "4",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "6": {
    "inputs": {
      "guidance": 3.5,
      "conditioning": [
        "5",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "7": {
    "inputs": {
      "noise_seed": 245726646861906
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "8": {
    "inputs": {
      "width": 576,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "9": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "10": {
    "inputs": {
      "scheduler": "simple",
      "steps": 8,
      "denoise": 1,
      "model": [
        "34",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "BasicScheduler"
    }
  },
  "11": {
    "inputs": {
      "model": [
        "17",
        0
      ],
      "conditioning": [
        "6",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "BasicGuider"
    }
  },
  "12": {
    "inputs": {
      "noise": [
        "7",
        0
      ],
      "guider": [
        "11",
        0
      ],
      "sampler": [
        "9",
        0
      ],
      "sigmas": [
        "10",
        0
      ],
      "latent_image": [
        "8",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "SamplerCustomAdvanced"
    }
  },
  "13": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "14": {
    "inputs": {
      "samples": [
        "12",
        0
      ],
      "vae": [
        "13",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "15": {
    "inputs": {
      "filename_prefix": "image",
      "images": [
        "32",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "17": {
    "inputs": {
      "lora_name": "FLUX.1-TURBO-ALPHA.safetensors",
      "strength_model": 1.0000000000000002,
      "model": [
        "1",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "31": {
    "inputs": {
      "model_name": "4x-UltraSharp.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "32": {
    "inputs": {
      "upscale_model": [
        "31",
        0
      ],
      "image": [
        "14",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "34": {
    "inputs": {
      "model_type": "flux",
      "rel_l1_thresh": 0.4,
      "max_skip_steps": 3,
      "model": [
        "17",
        0
      ]
    },
    "class_type": "TeaCache",
    "_meta": {
      "title": "TeaCache"
    }
  }
}